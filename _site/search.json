[
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "chess_board_segmentation.html",
    "href": "chess_board_segmentation.html",
    "title": "Chess Board Segmentation",
    "section": "",
    "text": "Applying Color Filtering to Image to isolate Red color\nTo segment the chess board from the environment, I am using a trick by coloring the boundaries of my chessboard as you can see in the below image.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport cv2\n\n# image = cv2.imread('data/IMG_20230706_204254.jpg')\nimage = cv2.imread('utilities/video_frames/frame_240.jpg')\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# convert to LAB color space\nlab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n\n# Perform Otsu threshold on the A-channel \nth = cv2.threshold(lab[:,:,1], 127, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n\n# Display the image using Matplotlib\nplt.imshow(th)\nplt.axis('off')\nplt.show()\n\n\n\n\n\nThe first step in the segmentation algorithm is to use the red boundary and isolate it from the full image.\n\n\nCode\nimport numpy as np\n\nresult = image.copy()\nhsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n# Define the lower and upper red color thresholds in HSV\nlower_red = np.array([0, 100, 100])\nupper_red = np.array([10, 255, 255])\n\n# Create a mask to filter out red pixels\nmask = cv2.inRange(hsv_image, lower_red, upper_red)\n\n# Apply the mask to the original image\nresult = cv2.bitwise_and(image, image, mask=th)\n\nfig, ax = plt.subplots(nrows=1, ncols=2)\nax[0].set_title('Loaded Sample Image')\nax[0].imshow(image_rgb)\nax[0].axis('off')\nax[1].set_title('Red Color Segmented')\nax[1].imshow(result)\nax[1].axis('off')\n\nplt.tight_layout()\nplt.axis('off')\n# Display the plot\nplt.show()\n\n\n\n\n\nLet’s break down the core logic of the code step by step:\n\nDefining Color Range for Filtering\n\nlower1 = np.array([0, 100, 20])\nupper1 = np.array([10, 255, 255])\nlower2 = np.array([160, 100, 20])\nupper2 = np.array([179, 255, 255])\nIn these lines, we define the lower and upper boundaries of the color range we want to filter. Here, we specify a red color range using two sets of values. The first set (lower1 and upper1) represents the lower and upper boundaries for the hue component of red in the range of 0-10 and the second set (lower2 and upper2) for the hue component in the range of 160-180. The other components (100, 20, 255) represent the minimum and maximum values for saturation and value, respectively.\n\nApplying Color Filtering\n\nlower_mask = cv2.inRange(image, lower1, upper1)\nupper_mask = cv2.inRange(image, lower2, upper2)\nfull_mask = lower_mask + upper_mask\nresult = cv2.bitwise_and(result, result, mask=full_mask)\nIn these lines, we apply color filtering to the image using the cv2.inRange() function. We create two masks (lower_mask and upper_mask) by comparing the pixel values of the image within the specified color range. The cv2.bitwise_and() function is then used to apply the masks to the result image, resulting in a filtered image where only the pixels within the specified color range are preserved.\n\n\nIdentifying all the lines in the image using Classic straight-line Hough transform\nThe Hough transform is a simple algorithm commonly used in computer vision to detect lines and shapes in an image. It provides a robust method to identify geometric patterns by representing them in a parameter space known as the Hough space. The algorithm works by converting image space coordinates to parameter space, where each point in the parameter space corresponds to a possible line or shape in the image. By accumulating votes for different parameter combinations, the Hough transform identifies the most prominent lines or shapes based on the peaks in the parameter space. This approach is particularly useful for line detection, as it can handle various types of lines, including straight lines, curves, and even partially occluded or broken lines.\n\n\nCode\nfrom skimage.transform import hough_line, hough_line_peaks\nfrom skimage.color import rgb2gray\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimage_gray = rgb2gray(image_rgb)\n\n# Classic straight-line Hough transform\n# Set a precision of 0.5 degree.\ntested_angles = np.linspace(-np.pi / 2, np.pi / 2, 360, endpoint=False)\nh, theta, d = hough_line(rgb2gray(result), theta=tested_angles)\n\nplt.figure(figsize=(20,10))\nplt.imshow(image_gray, cmap='gray')\n\nfor _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n    (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n    plt.axline((x0, y0), slope=np.tan(angle + np.pi/2))\n\nplt.title('Detected lines')\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nHere is the explanation of the key part of code which does line detection using the Hough transform:\n\nGenerating tested angles\n\ntested_angles = np.linspace(-np.pi / 2, np.pi / 2, 360, endpoint=False)\nIn this line, the np.linspace() function generates an array of 360 equally spaced angles between -np.pi / 2 and np.pi / 2. These angles represent the range of lines to be tested during the Hough transform. The endpoint=False argument ensures that the endpoint is not included in the generated array.\n\nPerforming the Hough transform\n\nh, theta, d = hough_line(rgb2gray(result), theta=tested_angles)\nHere, the hough_line() function is applied to the grayscale version of the result image using rgb2gray() to convert it. The theta parameter is set to the tested_angles array, which specifies the angles to consider during the transform. The resulting Hough accumulator array h, along with the theta angles theta and distances d, are stored.\n\n\nCode\nplt.title(\"hough transform visualization\")\nplt.imshow(np.log(1 + h),\n           extent=[np.rad2deg(theta[-1]), np.rad2deg(theta[0]), d[-1], d[0]],\n           cmap='gray', aspect='auto')\n\n\n&lt;matplotlib.image.AxesImage at 0x7f150a3df280&gt;\n\n\n\n\n\n\nDetecting and visualizing the lines\n\nfor _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n    (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n    plt.axline((x0, y0), slope=np.tan(angle + np.pi/2))\nThis loop iterates through the peaks detected in the Hough transform using the hough_line_peaks() function. For each peak, the angle and dist values represent the orientation and distance from the origin to a line in the image. The (x0, y0) coordinates are calculated by multiplying the distance with the [np.cos(angle), np.sin(angle)] vector, which determines the line’s position. Finally, plt.axline() is used to draw a line on the plot using the calculated (x0, y0) coordinates and the tangent of the angle plus np.pi/2.\nBy running this code, you will perform the Hough transform to detect lines in an image. The resulting lines will be visualized on a plot using plt.axline(). This code segment is useful for line detection applications and helps to understand the concept of identifying lines in an image using the Hough transform.\n\n\nFind all points of intersections of the lines\nTo extract the end points of the chess board, we need to find the intersection of the Hough lines.\n\n\nCode\nimport math \n\ndef find_intersection_point(fp_x0, fp_y0, slope1, sp_x0, sp_y0, slope2):\n    if (slope1 - slope2) == 0:\n      return []\n\n    # Calculate the intersection point coordinates\n    x_intersect = (sp_y0 - fp_y0 + slope1 * fp_x0 - slope2 * sp_x0) / (slope1 - slope2)\n    y_intersect = slope1 * (x_intersect - fp_x0) + fp_y0\n\n    if x_intersect &lt; 0 or y_intersect &lt; 0 or x_intersect &gt; 4000 or y_intersect &gt; 4000:\n      return []\n\n    angle_of_intersection =  math.degrees(math.atan((slope1-slope2)/(1+slope1*slope2)))\n\n    if angle_of_intersection &lt; 45 and angle_of_intersection &gt; -45:\n      return []\n\n    # Intersection point coordinates\n    intersection_point = [x_intersect, y_intersect]\n\n    return intersection_point\n\nlines = []\nall_points_and_slopes = []\nfor _, angle, dist in zip(*hough_line_peaks(h, theta, d)):\n    (x0, y0) = dist * np.array([np.cos(angle), np.sin(angle)])\n    lines.append([x0, y0, angle])\n    # ax[2].axline((x0, y0), slope=np.tan(angle + np.pi/2))\n    # ax[2].scatter(x0, y0)\n    slope = np.tan(angle + np.pi/2)\n    all_points_and_slopes.append([x0, y0, slope])\n\n# find intersection points\nintersection_points = []\nfor i in range(len(all_points_and_slopes)):\n  for j in range(1, len(all_points_and_slopes)):\n    p1 = all_points_and_slopes[i]\n    p2 = all_points_and_slopes[j]\n\n    ip = find_intersection_point(p1[0], p1[1], p1[2], p2[0], p2[1], p2[2])\n    if ip:\n      intersection_points.append(ip)\n\nintersection_points = np.array(intersection_points)\n\nplt.figure(figsize=(20,10))\nplt.imshow(image_gray, cmap='gray')\nplt.scatter(intersection_points[:, 0], intersection_points[:, 1], color='r')\nplt.title('Detected points of intersections')\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nBut as you can see, there are simply too many points due to too many intersecting lines. We are mainly intereseted in just 4 points which represent the 4 corners of the chess board. We can use KMeans algorithm with a cluster size of 4 to group the close together points. The K-means clustering algorithm is commonly used for unsupervised learning tasks to group similar data points together. It is an iterative algorithm that aims to minimize the within-cluster variance by adjusting the cluster centroids until convergence.\n\n\nCode\nfrom sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=4, random_state=0, n_init=\"auto\").fit(intersection_points)\n\nplt.figure(figsize=(20,10))\nplt.imshow(image_gray, cmap='gray')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], color='r')\nplt.title('Detected points of intersections')\n\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nkmeans = KMeans(n_clusters=4, random_state=0, n_init=\"auto\").fit(intersection_points)\nHere, the KMeans class is instantiated with the following parameters: - n_clusters=4: Specifies the number of clusters to form. In this case, we want to create four clusters. - random_state=0: Sets the random seed for reproducibility. By setting a specific random state value, the clustering results will be the same each time the code is run with the same data. - n_init=\"auto\": Determines the number of times the K-means algorithm will be run with different centroid seeds. “auto” automatically selects a value based on the number of data points.\nThe fit() method is then called on the KMeans object, with intersection_points as the input data. This fits the K-means model to the data, performing the clustering and assigning each data point to one of the four clusters.\nThe result of running the fit() method is stored in the kmeans variable. This object contains information about the fitted K-means model, including the cluster assignments for each data point.\nBy examining the kmeans object, you can access various properties and methods, such as kmeans.labels_ to retrieve the assigned cluster labels for each data point or kmeans.cluster_centers_ to obtain the centroid coordinates of each cluster.\n\n\nConnect the 4 points into a polygon\nWe use the standard convexHull algorithm to sort the 4 points in the order in which one can connect them into a polygon. Convex hull is a concept in computational geometry that represents the smallest convex polygon that encloses a given set of points in a plane.\n\n\nCode\nfrom scipy.spatial import ConvexHull\npoints = kmeans.cluster_centers_\nhull = ConvexHull(points)\n\nplt.figure(figsize=(20,10))\nplt.imshow(image_gray, cmap='gray')\nplt.plot(points[:,0], points[:,1], 'o', color='r')\nfor simplex in hull.simplices:\n    plt.plot(points[simplex, 0], points[simplex, 1], color='r')\nplt.axis('off')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nRemove the rest of the environment\nits a simple crop based on the polygon I generated from Convexhull calculation\n\n\nCode\nfrom skimage import draw\n\npoints = kmeans.cluster_centers_\npolygon_points = []\nfor k in hull.vertices:\n  polygon_points.append(points[k])\n\npolygon_points = np.array(polygon_points)\n\n# Create a mask of the polygon region\nmask = np.zeros(image_rgb.shape[:2], dtype=np.uint8)\nrr, cc = draw.polygon(polygon_points[:, 1], polygon_points[:, 0])\nmask[rr, cc] = 1\n\n# Apply the mask to the input image\ncropped_image = image_rgb.copy()\ncropped_image[mask == 0] = 0\nplt.figure(figsize=(20,10))\nplt.imshow(cropped_image)\nplt.axis('off')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Muthukrishnan",
    "section": "",
    "text": "Hey there, fellow adventurers! Welcome to my corner of this research notebook. I’m Muthukrishnan, your friendly neighborhood software engineer.\nI thrive on curiosity and a thirst for knowledge, constantly seeking new experiences and learning opportunities. Whether it’s diving into the depths of a gripping novel or immersing myself in the vibrant world of coding, I find joy in expanding my horizons.\nAs a tech enthusiast, I’m constantly amazed by the boundless possibilities it brings. From tinkering with gadgets to exploring the ever-evolving world of AI, I’m enthralled by the exciting intersection of humanity and innovation.\nIf you ask me my favorite miracles, it would be the Euler’s Identity and the Butterfly curve.\nEuler’s Identity \\[\\begin{gather*}\ne^{i\\pi }+1=0\n\\end{gather*}\\]\nButterfly curve \\[\\begin{gather*}\n{\\displaystyle x=\\sin t\\!\\left(e^{\\cos t}-2\\cos 4t-\\sin ^{5}\\!{\\Big (}{t \\over 12}{\\Big )}\\right)}\n\\end{gather*}\\]\n\\[\\begin{gather*}\n{\\displaystyle y=\\cos t\\!\\left(e^{\\cos t}-2\\cos 4t-\\sin ^{5}\\!{\\Big (}{t \\over 12}{\\Big )}\\right)}\n\\end{gather*}\\]\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameterize the butterfly curve equation\nt = np.linspace(0, 2 * np.pi, 1000)\nx = np.sin(t) * (np.exp(np.cos(t)) - 2 * np.cos(4 * t) - np.sin(t / 12) ** 5)\ny = np.cos(t) * (np.exp(np.cos(t)) - 2 * np.cos(4 * t) - np.sin(t / 12) ** 5)\n\n# Plot the butterfly curve\nplt.plot(x, y, color='red', linewidth=1)\nplt.title(\"Butterfly curve\")\nplt.axis('equal')\n\n# Display the plot\nplt.show()\n\n\n\n\n\nSo, dear reader, join me on this thrilling journey as we navigate through the twists and turns of life. Together, let’s discover new passions, celebrate the extraordinary, and revel in the joy of being wonderfully unique.\nFasten your seatbelts, embrace your sense of wonder, and let’s embark on an unforgettable adventure together!\nI also blog at muthu.co, you can read about the Euler’s formula here"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Muthukrishnan",
    "section": "",
    "text": "Hey there, fellow adventurers! Welcome to my corner of this research notebook. I’m Muthukrishnan, your friendly neighborhood software engineer.\nI thrive on curiosity and a thirst for knowledge, constantly seeking new experiences and learning opportunities. Whether it’s diving into the depths of a gripping novel or immersing myself in the vibrant world of coding, I find joy in expanding my horizons.\nAs a tech enthusiast, I’m constantly amazed by the boundless possibilities it brings. From tinkering with gadgets to exploring the ever-evolving world of AI, I’m enthralled by the exciting intersection of humanity and innovation.\nIf you ask me my favorite miracles, it would be the Euler’s Identity and the Butterfly curve.\nEuler’s Identity \\[\\begin{gather*}\ne^{i\\pi }+1=0\n\\end{gather*}\\]\nButterfly curve \\[\\begin{gather*}\n{\\displaystyle x=\\sin t\\!\\left(e^{\\cos t}-2\\cos 4t-\\sin ^{5}\\!{\\Big (}{t \\over 12}{\\Big )}\\right)}\n\\end{gather*}\\]\n\\[\\begin{gather*}\n{\\displaystyle y=\\cos t\\!\\left(e^{\\cos t}-2\\cos 4t-\\sin ^{5}\\!{\\Big (}{t \\over 12}{\\Big )}\\right)}\n\\end{gather*}\\]\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameterize the butterfly curve equation\nt = np.linspace(0, 2 * np.pi, 1000)\nx = np.sin(t) * (np.exp(np.cos(t)) - 2 * np.cos(4 * t) - np.sin(t / 12) ** 5)\ny = np.cos(t) * (np.exp(np.cos(t)) - 2 * np.cos(4 * t) - np.sin(t / 12) ** 5)\n\n# Plot the butterfly curve\nplt.plot(x, y, color='red', linewidth=1)\nplt.title(\"Butterfly curve\")\nplt.axis('equal')\n\n# Display the plot\nplt.show()\n\n\n\n\n\nSo, dear reader, join me on this thrilling journey as we navigate through the twists and turns of life. Together, let’s discover new passions, celebrate the extraordinary, and revel in the joy of being wonderfully unique.\nFasten your seatbelts, embrace your sense of wonder, and let’s embark on an unforgettable adventure together!\nI also blog at muthu.co, you can read about the Euler’s formula here"
  },
  {
    "objectID": "utilities/video to images.html",
    "href": "utilities/video to images.html",
    "title": "Extract Image frames from Video",
    "section": "",
    "text": "Code\nimport skimage.io\nimport os\n\n# Get the path to the video file.\nvideo_file = \"utilities/data/VOD_20230708_062617.mp4\"\n\nimport cv2\nimport os\n\n# Create a directory to store the images.\nimage_dir = \"video_frames\"\nif not os.path.exists(image_dir):\n    os.mkdir(image_dir)\n\n# Get the number of frames in the video.\ncap = cv2.VideoCapture(video_file)\nnum_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n# Iterate over the frames in the video and save them as images.\nfor i in range(num_frames):\n    ret, frame = cap.read()\n    if not ret:\n        continue\n    image_name = \"frame_{}.jpg\".format(i)\n    cv2.imwrite(os.path.join(image_dir, image_name), frame)\n\ncap.release()"
  },
  {
    "objectID": "utilities/video_to_images.html",
    "href": "utilities/video_to_images.html",
    "title": "Extract Image frames from Video",
    "section": "",
    "text": "import skimage.io\nimport os\n\n# Get the path to the video file.\nvideo_file = \"data/VOD_20230708_062617.mp4\"\n\nimport cv2\nimport os\n\n# Create a directory to store the images.\nimage_dir = \"video_frames\"\nif not os.path.exists(image_dir):\n    os.mkdir(image_dir)\n\n# Get the number of frames in the video.\ncap = cv2.VideoCapture(video_file)\nnum_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n# Iterate over the frames in the video and save them as images.\nfor i in range(num_frames):\n    ret, frame = cap.read()\n    if not ret:\n        continue\n    image_name = \"frame_{}.jpg\".format(i)\n    cv2.imwrite(os.path.join(image_dir, image_name), frame)\n\ncap.release()"
  }
]